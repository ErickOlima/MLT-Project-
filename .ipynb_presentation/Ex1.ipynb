{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0dd33bb0",
   "metadata": {},
   "source": [
    "## importando depedências"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e8850923",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as t\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import tqdm\n",
    "import Rede_neural as rn\n",
    "import Treinamenro_de_rede_show as tr\n",
    "import time as tm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f7b6268",
   "metadata": {},
   "source": [
    "## Definindo os parâmetros de treinamento"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e29cc90",
   "metadata": {},
   "source": [
    " - Estamos utilizando como a média dos quadrados dos desvios obtidos para cada caso de treinamento utilizando a função torch.nn.MSELoss() \n",
    " - O treinamento foi feito em batchs com todos os casos de treinamento\n",
    " - O otimizador utilizado foi o Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c51fd88f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ---- definido parâmetros ---- \n"
     ]
    }
   ],
   "source": [
    "print(\" ---- definido parâmetros ---- \")\n",
    "\n",
    "#dicionário com os erros de diversas situações\n",
    "dict_erros = {}\n",
    "\n",
    "#função\n",
    "func = lambda x: x ** 3\n",
    "#amostras \n",
    "number_samples = 20\n",
    "xa, xb = -4, 4\n",
    "#t.manual_seed(0)\n",
    "x_train = xa + (xb-xa) * t.rand(number_samples, 1)\n",
    "y_train = func(x_train)\n",
    "\n",
    "x_val = xa + (xb-xa) * t.rand(number_samples, 1)\n",
    "y_val = func(x_val)\n",
    "\n",
    "#valores de validação\n",
    "xf = np.linspace(-6, 6, 12)\n",
    "\n",
    "#erro de função\n",
    "''' função utilizada para estimar a qualidade do resultado proposto pela rede considerando o intervalo de -6 a 6'''\n",
    "error_func = t.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0de60d90",
   "metadata": {},
   "source": [
    "## Melhor rede para o problema"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "326fe2b4",
   "metadata": {},
   "source": [
    "Testando para todas as redes que são compostas considerando o número de camadas nas camadas internas de 5, 10, 15, 20, 25 e 30 para com até 3 camadas e os resultados de um método adpatado do método da secante, se encontrou como melhor rede a rede com a função de ativação RELU e 15 neuronios na 1ª camada e 5 na 2ª camada. O melhor resultado para as redes com funções de ativação Sigmoid e Tanh se deram com respectivamente: 7 neuronios na 1ª camada e 672 na 2ª camada; e 1000 neuronios na 1ª camada (considerado como o número máximo de neuronios para a análise pelo método iterativo)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c23cc62",
   "metadata": {},
   "source": [
    "### Rede RELU com 15 neuronios na 1ª camada e 5 na 2ª camada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fa79b7a0",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'Rede_neural' has no attribute 'plotagem_1d_modelo_show'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m neuronios \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m15\u001b[39m, \u001b[38;5;241m5\u001b[39m]\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# \u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m erro_extrapol \u001b[38;5;241m=\u001b[39m \u001b[43mtr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocessamento_agrupado\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mneural_net_interno_2_hidden\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mneuronios\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactivation_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror_func\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Gabriel\\Desktop\\estudo\\unicamp\\10 Semestre\\CV970 - Redes Neurais\\trabalhos\\MLT-Project-\\.ipynb_presentation\\Treinamenro_de_rede_show.py:57\u001b[0m, in \u001b[0;36mprocessamento_agrupado\u001b[1;34m(model_class, neuronios, activation_func, x_train, y_train, x_val, y_val, xf, func, error_func)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(neuronios)):\n\u001b[0;32m     56\u001b[0m     text \u001b[38;5;241m=\u001b[39m text \u001b[38;5;241m+\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_hidden\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mneuronios[i]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 57\u001b[0m \u001b[43mrn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplotagem_1d_modelo_show\u001b[49m(xf, func, y_pred, x_train, y_train, x_val, y_val, loss_train, loss_val, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my = x³\u001b[39m\u001b[38;5;124m\"\u001b[39m,text)\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m error_measure\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'Rede_neural' has no attribute 'plotagem_1d_modelo_show'"
     ]
    }
   ],
   "source": [
    "# função de ativação\n",
    "activation_func = \"ReLU\"\n",
    "# número de neuronios\n",
    "neuronios = [15, 5]\n",
    "\n",
    "# processamento da rede e plotagem das funções\n",
    "erro_extrapol = tr.processamento_agrupado(rn.neural_net_interno_2_hidden, neuronios, activation_func, x_train, y_train, x_val, y_val, xf, func, error_func)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "54671cc2",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'Rede_neural' has no attribute 'plotagem_1d_modelo_show'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mrn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplotagem_1d_modelo_show\u001b[49m()\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'Rede_neural' has no attribute 'plotagem_1d_modelo_show'"
     ]
    }
   ],
   "source": [
    "rn.plotagem_1d_modelo_show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98b752a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "        for neuronios_1 in (5, 10, 15, 20, 25, 30):\n",
    "            model = rn.neural_net_interno_1_hidden([1, neuronios_1, 1], activation_func, zerar_seed=1) # uma camada interna de 20]\n",
    "            loss = model.treino(x_true, y_true)\n",
    "\n",
    "            y_pred = model.foward(t.tensor(np.array([xf]).T, dtype = t.float32)).squeeze()\n",
    "\n",
    "            error_measure = error_func(t.tensor(func(xf), dtype= t.float32), y_pred).item()\n",
    "            dict_erros[activation_func][neuronios_1] = error_measure\n",
    "\n",
    "            plotagem_1d_modelo(xf, func, x_true, y_pred, y_true, loss, \"y = x³\",\n",
    "                                f\"Work\\Ex1_graphs\\{activation_func}_hidden1_{neuronios_1}\")\n",
    "            pbar.update(1)\n",
    "\n",
    "        # 2 hidden layer\n",
    "        for neuronios_1 in neuronios_list:\n",
    "            for neuronios_2 in neuronios_list:\n",
    "                model = rn.neural_net_interno_2_hidden([1, neuronios_1, neuronios_2, 1], activation_func) # uma camada interna de 20]\n",
    "                loss = model.treino(x_true, y_true)\n",
    "\n",
    "                y_pred = model.foward(t.tensor(np.array([xf]).T, dtype = t.float32)).squeeze()\n",
    "\n",
    "                error_measure = error_func(t.tensor(func(xf), dtype= t.float64), y_pred).item()\n",
    "                dict_erros[activation_func][f\"{neuronios_1},{neuronios_2}\"] = error_measure\n",
    "\n",
    "                plotagem_1d_modelo(xf, func, x_true, y_pred, y_true, loss, \"y = x³\",\n",
    "                                    f\"Work\\Ex1_graphs\\{activation_func}_hidden1_{neuronios_1}_hidden2_{neuronios_2}\")\n",
    "                pbar.update(1)\n",
    "        # 3 hidden layer\n",
    "        for neuronios_1 in neuronios_list:\n",
    "            for neuronios_2 in neuronios_list:\n",
    "                for neuronios_3 in neuronios_list:\n",
    "                    model = rn.neural_net_interno_3_hidden([1, neuronios_1, neuronios_2, neuronios_3, 1], activation_func) # uma camada interna de 20]\n",
    "                    loss = model.treino(x_true, y_true)\n",
    "\n",
    "                    y_pred = model.foward(t.tensor(np.array([xf]).T, dtype = t.float32)).squeeze()\n",
    "\n",
    "                    error_measure = error_func(t.tensor(func(xf), dtype= t.float64), y_pred).item()\n",
    "                    dict_erros[activation_func][f\"{neuronios_1},{neuronios_2},{neuronios_3}\"] = error_measure\n",
    "\n",
    "                    plotagem_1d_modelo(xf, func, x_true, y_pred, y_true, loss, \"y = x³\",\n",
    "                                        f\"Work\\Ex1_graphs\\{activation_func}_hidden1_{neuronios_1}_hidden2_{neuronios_2}_hidden3_{neuronios_3}\")\n",
    "                    pbar.update(1)\n",
    "\n",
    "        for erros in dict_erros[activation_func].items():\n",
    "            print(f\"Função de Ativação: {activation_func}, Neurônios: {erros[0]}, Erro: {erros[1]}\")\n",
    "        \n",
    "        print(f\"Tempo para função de ativação {activation_func}: {tm.time()-begin:.2f} segundos\")\n",
    "\n",
    "print(\" ---- salvando erros ---- \")\n",
    "dict_erros = json.dumps(dict_erros)\n",
    "with open(\"Work\\Ex1_graphs\\Erros.txt\", \"w\") as file:\n",
    "    print(dict_erros, file=file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
