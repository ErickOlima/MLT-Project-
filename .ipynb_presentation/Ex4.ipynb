{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ef6d269",
   "metadata": {},
   "source": [
    "# Exercício 4\n",
    "**Nome:** Erick         **Ra.** 240197\\\n",
    "**Nome:** Gabriel       **Ra.** 240254\n",
    "## Importando depedências"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c36c3111",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ---- importando dependências ---- \n"
     ]
    }
   ],
   "source": [
    "import torch as t\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import tqdm\n",
    "import Rede_neural as rn\n",
    "import time as tm\n",
    "import Treinamenro_de_rede as tr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d4d2da5",
   "metadata": {},
   "source": [
    "## Definindo os parâmetros de treinamento\n",
    " - Estamos utilizando como a média dos quadrados dos desvios obtidos para cada caso de treinamento utilizando a função torch.nn.MSELoss() \n",
    " - O treinamento foi feito em batchs com todos os casos de treinamento\n",
    " - O otimizador utilizado foi o Adam\n",
    " - Os pesos da rede foram adotados na situação onde a perda dos dados de validação (não extrapolação) é mínima"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "494722a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ---- definido parâmetros ---- \n",
      " ---- treinando e validando a rede ---- \n"
     ]
    }
   ],
   "source": [
    "#função\n",
    "func = lambda x_1,x_2: x_1 ** 2 + x_2 ** 2 -10*(t.cos(t.pi*x_1) + t.cos(t.pi*x_2))\n",
    "\n",
    "#amostras \n",
    "number_samples = 30\n",
    "xa, xb = -5, 5\n",
    "t.manual_seed(0)\n",
    "\n",
    "input_size = 2\n",
    "output_size = 1\n",
    "\n",
    "x_train = xa + (xb-xa) * t.rand(number_samples, input_size)\n",
    "x_val = xa + (xb-xa) * t.rand(number_samples, input_size)\n",
    "\n",
    "y_train = func(x_train[:,0], x_train[:,1])\n",
    "y_val = func(x_val[:,0], x_val[:,1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "596196f9",
   "metadata": {},
   "source": [
    "## Melhor rede para o problema\n",
    "Testando para todas as redes que são compostas considerando o número de camadas de até 6 os resultados de um método adpatado do método da secante, se encontrou como melhor rede a rede com a função de ativação RELU  de 6 camadas com respectivamente 10, 52, 19, 71, 44 e 58 nerrônios por camada. O melhor resultado para as redes com funções de ativação Sigmoid foi com dadas 2 camadas com respectivamente 18 e 4 reunônios dispostos. já para a função de ativação to tipo tanh o melhor resdultado foi obserdo com 6 camadas das quais foram dispostos 95, 168, 177, 47, 79, e 994 neurônios em cada uma delas.  \n",
    "### Rede RELU com 6 camadas e uma distribuição de neurînios por camada: 10 na 1ª, 52 na 2ª, 19 na 3ª, 71 na 4ª, 44 na 5ª, 58 na 6ª (Melhor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a009af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# função de ativação\n",
    "activation_func = \"ReLU\"\n",
    "\n",
    "# número de neuronios\n",
    "neuronios = [10, 52, 19, 71, 44, 58]\n",
    "\n",
    "# processamento da rede e plotagem das funções\n",
    "loss_val_min = tr.processamento_agrupado_2d(rn.neural_net_interno_6_hidden, neuronios, activation_func, x_train, y_train, x_val, y_val, func, xa, xb)\n",
    "\n",
    "# printando preda mínima dos dados de validação\n",
    "print(f\"perda estimada = {loss_val_min}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9e8f34f",
   "metadata": {},
   "source": [
    "### Rede Sigmoid com 2 camdas com a configuração de 18 neurônios na 1ª e 4 na 2ª ( melhor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbeee317",
   "metadata": {},
   "outputs": [],
   "source": [
    "# função de ativação\n",
    "activation_func = \"sigmoid\"\n",
    "\n",
    "# número de neuronios\n",
    "neuronios = [18,4]\n",
    "\n",
    "# processamento da rede e plotagem das funções\n",
    "loss_val_min = tr.processamento_agrupado_2d(rn.neural_net_interno_2_hidden, neuronios, activation_func, x_train, y_train, x_val, y_val, func, xa, xb)\n",
    "\n",
    "# printando preda mínima dos dados de validação\n",
    "print(f\"perda estimada = {loss_val_min}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "872fbe8d",
   "metadata": {},
   "source": [
    "### Rede Tanh com  6 camadas das quais foram distribuidos 95 na 1ª, 168 na 2ª, 177 na 3ª, 47 na 4ª, 79 5ª e 994 na 6ª ( melhor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f8410e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# função de ativação\n",
    "activation_func = \"tanh\"\n",
    "\n",
    "# número de neuronios\n",
    "neuronios = [95, 168, 177, 47, 79, 994]\n",
    "\n",
    "# processamento da rede e plotagem das funções\n",
    "loss_val_min = tr.processamento_agrupado_2d(rn.neural_net_interno_6_hidden, neuronios, activation_func, x_train, y_train, x_val, y_val, func, xa, xb)\n",
    "\n",
    "# printando preda mínima dos dados de validação\n",
    "print(f\"perda estimada = {loss_val_min}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fadfc28",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
